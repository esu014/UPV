{"cells":[{"cell_type":"markdown","metadata":{"id":"fXgAhyAdgyvS"},"source":["# Perceptrón aplicado a iris"]},{"cell_type":"markdown","metadata":{"id":"qMuI1k_AgyvT"},"source":["**Lectura del corpus:** $\\;$ comprobamos también que las matrices de datos y etiquetas tienen las filas y columnas que toca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KqKpXRcFgyvU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3849857c-e40a-45e6-e486-686f671e554a"},"outputs":[{"output_type":"stream","name":"stdout","text":["downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data\n","(400, 4096) (400, 1) \n"," [[0.30981445 0.36767578 0.41723633 ... 0.16113281 0.15698242 0.        ]\n"," [0.45458984 0.47119141 0.51220703 ... 0.15283203 0.15283203 0.        ]\n"," [0.31811523 0.40087891 0.49169922 ... 0.14880371 0.15283203 0.        ]\n"," [0.19836426 0.19421387 0.19421387 ... 0.75195312 0.73974609 0.        ]\n"," [0.5        0.54541016 0.58251953 ... 0.17358398 0.17358398 0.        ]]\n"]}],"source":["import numpy as np; from sklearn.datasets import fetch_olivetti_faces\n","iris = fetch_olivetti_faces(); X = iris.data.astype(np.float16);\n","y = iris.target.astype(np.uint).reshape(-1, 1);\n","print(X.shape, y.shape, \"\\n\", np.hstack([X, y])[:5, :])"]},{"cell_type":"markdown","metadata":{"id":"bNj7PTU5gyvU"},"source":["**Partición del corpus:** $\\;$ Creamos un split de iris con un $20\\%$ de datos para test y el resto para entrenamiento (training), barajando previamente los datos de acuerdo con una semilla dada para la generación de números aleatorios. Aquí, como en todo código que incluya aleatoriedad (que requiera generar números aleatorios), conviene fijar dicha semilla para poder reproducir experimentos con exactitud."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3JVbmXUgyvV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"516155d4-2ae5-46b0-808e-730744472914"},"outputs":[{"output_type":"stream","name":"stdout","text":["(320, 4096) (80, 4096)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n","print(X_train.shape, X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"Qy73P_ssgyvV"},"source":["**Implementación de Perceptrón:** $\\;$ devuelve pesos en notación homogénea, $\\mathbf{W}\\in\\mathbb{R}^{(1+D)\\times C};\\;$ también el número de errores e iteraciones ejecutadas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIzbuFofgyvV"},"outputs":[],"source":["def perceptron(X, y, b=0.1, a=1.0, K=200):\n","    N, D = X.shape; Y = np.unique(y); C = Y.size; W = np.zeros((1+D, C))\n","    for k in range(1, K+1):\n","        E = 0\n","        for n in range(N):\n","            xn = np.array([1, *X[n, :]])\n","            cn = np.squeeze(np.where(Y==y[n]))\n","            gn = W[:,cn].T @ xn; err = False\n","            for c in np.arange(C):\n","                if c != cn and W[:,c].T @ xn + b >= gn:\n","                    W[:, c] = W[:, c] - a*xn; err = True\n","            if err:\n","                W[:, cn] = W[:, cn] + a*xn; E = E + 1\n","        if E == 0:\n","            break;\n","    return W, E, k"]},{"cell_type":"markdown","metadata":{"id":"y31EDfj7gyvW"},"source":["**Aprendizaje de un clasificador (lineal) con Perceptrón:** $\\;$ Perceptrón minimiza el número de errores de entrenamiento (con margen)\n","$$\\mathbf{W}^*=\\operatorname*{argmin}_{\\mathbf{W}=(\\boldsymbol{w}_1,\\dotsc,\\boldsymbol{w}_C)}\\sum_n\\;\\mathbb{Y}\\biggl(\\max_{c\\neq y_n}\\;\\boldsymbol{w}_c^t\\boldsymbol{x}_n+b \\;>\\; \\boldsymbol{w}_{y_n}^t\\boldsymbol{x}_n\\biggr)$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAuEF10bgyvX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b23770e0-c9c3-40fa-ac93-6e343109efc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de iteraciones ejecutadas:  42\n","Número de errores de entrenamiento:  0\n","Vectores de pesos de las clases (en columnas y en notación homogénea):\n"," [[-587.         -581.         -581.         ... -590.\n","  -557.         -585.        ]\n"," [-247.08929443 -233.21960449 -244.16125488 ... -266.64141846\n","  -244.67816162 -239.23931885]\n"," [-265.13061523 -251.18511963 -267.29406738 ... -281.07702637\n","  -270.37103271 -256.94555664]\n"," ...\n"," [-211.28652954 -203.89273071 -199.72198486 ... -196.6746521\n","  -201.48944092 -207.01318359]\n"," [-205.98419189 -202.98080444 -198.18414307 ... -194.52960205\n","  -195.22445679 -199.60604858]\n"," [-206.72164917 -203.47958374 -198.56820679 ... -189.42913818\n","  -192.849823   -194.80505371]]\n"]}],"source":["W, E, k = perceptron(X_train, y_train)\n","print(\"Número de iteraciones ejecutadas: \", k)\n","print(\"Número de errores de entrenamiento: \", E)\n","print(\"Vectores de pesos de las clases (en columnas y en notación homogénea):\\n\", W);"]},{"cell_type":"markdown","metadata":{"id":"u7G-a5_zgyvX"},"source":["**Cálculo de la tasa de error en test:**\n","El siguiente conjunto de instrucciones calcula la tasa de error para un Perceptron entrenado con b=0.1 y a=1.0 (factor de aprendizaje o 'a') y K=200 iteraciones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1W2qNWQggyvY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"93b65c8c-dbaf-4f2c-f923-1436f152748a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tasa de error en test: 7.5%\n"]}],"source":["X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n","y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n","err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n","print(f\"Tasa de error en test: {err_test:.1%}\")"]},{"cell_type":"code","source":["err_test * len(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qH2dVT9odSoK","outputId":"9517b542-9b77-4e16-b7a2-bc97328cb814"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6.0"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"43TAexM_gyvY"},"source":["**Ajuste del margen:** $\\;$ el siguiente bucle es un experimento que ejecuta 5 veces el algoritmo del Perceptron con 5 valores diferentes de $b$ y valor por defecto $α$=1.0 y K=1000 iteraciones, mostrando el error de entrenamiento para cada valor de $b$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EokibkXgyvY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"96e149e0-e78e-4461-8c66-0cdad30541be"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.0 0 48\n","0.01 0 58\n","0.1 0 42\n","10 0 45\n","100 0 72\n"]}],"source":["for b in (.0, .01, .1, 10, 100):\n","    W, E, k = perceptron(X_train, y_train, b=b, K=1000)\n","    print(b, E, k)"]},{"cell_type":"markdown","metadata":{"id":"faP8KC55gyvY"},"source":["**Interpretación de resultados:** $\\;$ los datos de entrenamiento no parecen linealmente separables; no está claro que un margen mayor que cero pueda mejorar resultados, sobre todo porque solo tenemos $30$ muestras de test; con margen nulo ya hemos visto que se obtiene un error (en test) del $16.7\\%$\n","-"]},{"cell_type":"code","source":["min_error = float('inf')\n","best_combination = None\n","print('# a b K E k Ete')\n","for a in (0.1,1.0,10,100,1000,10000):\n","  for b in (0.0,0.01,0.1,1.0,100,1000):\n","    for K in (200,500,800,1000):\n","      W, E, k = perceptron(X_train, y_train, b, a, K)\n","      X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n","      y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n","      err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n","      print('%8.2f %8.2f %6d %6d %6d %8.3f' %(a, b, K, E,k,err_test))\n","      if err_test < min_error:\n","                min_error = err_test\n","                best_combination = (a, b, k)\n","\n","  print('#------- ------ ---- ---- ---- ----')\n","print('Mejor combinación con menor error:', best_combination)\n","print('Menor error encontrado:', min_error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUssUWqheyU3","outputId":"065325f4-74b2-400b-a54a-c1d5fead18c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["# a b K E k Ete\n","    0.10     0.00    200      0     60    0.125\n","    0.10     0.00    500      0     60    0.125\n","    0.10     0.00    800      0     60    0.125\n","    0.10     0.00   1000      0     60    0.125\n","    0.10     0.01    200      0     42    0.075\n","    0.10     0.01    500      0     42    0.075\n","    0.10     0.01    800      0     42    0.075\n","    0.10     0.01   1000      0     42    0.075\n","    0.10     0.10    200      0     79    0.113\n","    0.10     0.10    500      0     79    0.113\n","    0.10     0.10    800      0     79    0.113\n","    0.10     0.10   1000      0     79    0.113\n","    0.10     1.00    200      0     45    0.150\n","    0.10     1.00    500      0     45    0.150\n","    0.10     1.00    800      0     45    0.150\n","    0.10     1.00   1000      0     45    0.150\n","    0.10   100.00    200      0     96    0.062\n","    0.10   100.00    500      0     96    0.062\n","    0.10   100.00    800      0     96    0.062\n","    0.10   100.00   1000      0     96    0.062\n","    0.10  1000.00    200    120    200    0.062\n","    0.10  1000.00    500      0    412    0.037\n","    0.10  1000.00    800      0    412    0.037\n","    0.10  1000.00   1000      0    412    0.037\n","#------- ------ ---- ---- ---- ----\n","    1.00     0.00    200      0     48    0.188\n","    1.00     0.00    500      0     48    0.188\n","    1.00     0.00    800      0     48    0.188\n","    1.00     0.00   1000      0     48    0.188\n","    1.00     0.01    200      0     58    0.113\n","    1.00     0.01    500      0     58    0.113\n","    1.00     0.01    800      0     58    0.113\n","    1.00     0.01   1000      0     58    0.113\n","    1.00     0.10    200      0     42    0.075\n","    1.00     0.10    500      0     42    0.075\n","    1.00     0.10    800      0     42    0.075\n","    1.00     0.10   1000      0     42    0.075\n","    1.00     1.00    200      0     79    0.113\n","    1.00     1.00    500      0     79    0.113\n","    1.00     1.00    800      0     79    0.113\n","    1.00     1.00   1000      0     79    0.113\n","    1.00   100.00    200      0     72    0.087\n","    1.00   100.00    500      0     72    0.087\n","    1.00   100.00    800      0     72    0.087\n","    1.00   100.00   1000      0     72    0.087\n","    1.00  1000.00    200      0     96    0.062\n","    1.00  1000.00    500      0     96    0.062\n","    1.00  1000.00    800      0     96    0.062\n","    1.00  1000.00   1000      0     96    0.062\n","#------- ------ ---- ---- ---- ----\n","   10.00     0.00    200      0     48    0.188\n","   10.00     0.00    500      0     48    0.188\n","   10.00     0.00    800      0     48    0.188\n","   10.00     0.00   1000      0     48    0.188\n","   10.00     0.01    200      0     48    0.188\n","   10.00     0.01    500      0     48    0.188\n","   10.00     0.01    800      0     48    0.188\n","   10.00     0.01   1000      0     48    0.188\n","   10.00     0.10    200      0     58    0.113\n","   10.00     0.10    500      0     58    0.113\n","   10.00     0.10    800      0     58    0.113\n","   10.00     0.10   1000      0     58    0.113\n","   10.00     1.00    200      0     42    0.075\n","   10.00     1.00    500      0     42    0.075\n","   10.00     1.00    800      0     42    0.075\n","   10.00     1.00   1000      0     42    0.075\n","   10.00   100.00    200      0     45    0.150\n","   10.00   100.00    500      0     45    0.150\n","   10.00   100.00    800      0     45    0.150\n","   10.00   100.00   1000      0     45    0.150\n","   10.00  1000.00    200      0     72    0.087\n","   10.00  1000.00    500      0     72    0.087\n","   10.00  1000.00    800      0     72    0.087\n","   10.00  1000.00   1000      0     72    0.087\n","#------- ------ ---- ---- ---- ----\n","  100.00     0.00    200      0     48    0.188\n","  100.00     0.00    500      0     48    0.188\n","  100.00     0.00    800      0     48    0.188\n","  100.00     0.00   1000      0     48    0.188\n","  100.00     0.01    200      0     48    0.188\n","  100.00     0.01    500      0     48    0.188\n","  100.00     0.01    800      0     48    0.188\n","  100.00     0.01   1000      0     48    0.188\n","  100.00     0.10    200      0     48    0.188\n","  100.00     0.10    500      0     48    0.188\n","  100.00     0.10    800      0     48    0.188\n","  100.00     0.10   1000      0     48    0.188\n","  100.00     1.00    200      0     58    0.113\n","  100.00     1.00    500      0     58    0.113\n","  100.00     1.00    800      0     58    0.113\n","  100.00     1.00   1000      0     58    0.113\n","  100.00   100.00    200      0     79    0.113\n","  100.00   100.00    500      0     79    0.113\n","  100.00   100.00    800      0     79    0.113\n","  100.00   100.00   1000      0     79    0.113\n","  100.00  1000.00    200      0     45    0.150\n","  100.00  1000.00    500      0     45    0.150\n","  100.00  1000.00    800      0     45    0.150\n","  100.00  1000.00   1000      0     45    0.150\n","#------- ------ ---- ---- ---- ----\n"," 1000.00     0.00    200      0     48    0.188\n"," 1000.00     0.00    500      0     48    0.188\n"," 1000.00     0.00    800      0     48    0.188\n"," 1000.00     0.00   1000      0     48    0.188\n"," 1000.00     0.01    200      0     48    0.188\n"," 1000.00     0.01    500      0     48    0.188\n"," 1000.00     0.01    800      0     48    0.188\n"," 1000.00     0.01   1000      0     48    0.188\n"," 1000.00     0.10    200      0     48    0.188\n"," 1000.00     0.10    500      0     48    0.188\n"," 1000.00     0.10    800      0     48    0.188\n"," 1000.00     0.10   1000      0     48    0.188\n"," 1000.00     1.00    200      0     48    0.188\n"," 1000.00     1.00    500      0     48    0.188\n"," 1000.00     1.00    800      0     48    0.188\n"," 1000.00     1.00   1000      0     48    0.188\n"," 1000.00   100.00    200      0     42    0.075\n"," 1000.00   100.00    500      0     42    0.075\n"," 1000.00   100.00    800      0     42    0.075\n"," 1000.00   100.00   1000      0     42    0.075\n"," 1000.00  1000.00    200      0     79    0.113\n"," 1000.00  1000.00    500      0     79    0.113\n"," 1000.00  1000.00    800      0     79    0.113\n"," 1000.00  1000.00   1000      0     79    0.113\n","#------- ------ ---- ---- ---- ----\n","10000.00     0.00    200      0     55    0.188\n","10000.00     0.00    500      0     55    0.188\n","10000.00     0.00    800      0     55    0.188\n","10000.00     0.00   1000      0     55    0.188\n","10000.00     0.01    200      0     48    0.188\n","10000.00     0.01    500      0     48    0.188\n","10000.00     0.01    800      0     48    0.188\n","10000.00     0.01   1000      0     48    0.188\n","10000.00     0.10    200      0     48    0.188\n","10000.00     0.10    500      0     48    0.188\n","10000.00     0.10    800      0     48    0.188\n","10000.00     0.10   1000      0     48    0.188\n","10000.00     1.00    200      0     48    0.188\n","10000.00     1.00    500      0     48    0.188\n","10000.00     1.00    800      0     48    0.188\n","10000.00     1.00   1000      0     48    0.188\n","10000.00   100.00    200      0     58    0.113\n","10000.00   100.00    500      0     58    0.113\n","10000.00   100.00    800      0     58    0.113\n","10000.00   100.00   1000      0     58    0.113\n","10000.00  1000.00    200      0     42    0.075\n","10000.00  1000.00    500      0     42    0.075\n","10000.00  1000.00    800      0     42    0.075\n","10000.00  1000.00   1000      0     42    0.075\n","#------- ------ ---- ---- ---- ----\n","Mejor combinación con menor error: (0.1, 1000, 412)\n","Menor error encontrado: 0.0375\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zRISKlhJirep"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ejercicio para realizar en clase:**\n","---\n","\n","\n","Escribe el código python necesario para mostrar resultados del error de entrenamiento (E), número de iteraciones empleadas (k) y error de test (err_test) para combinaciones de diferentes valores de:\n","---\n","\n","# *   a: (factor de aprendizaje: utiliza valores 0.1, 1.0, 10, 100, 1000, 10000)\n","# *   b: (margen: utiliza valores 0.0, 0.01, 0.1, 1.0, 100, 1000)\n","# *   K: (iteraciones: utiliza valores 200, 500, 800 y 1000)\n","\n","\n","Utiliza la siguientes instrucciones para mostrar la cabecera:\n","---\n","\n","`print('#      a        b      K      E      k      Ete');`\n","---\n","`print('#-------   ------   ----   ----   ----     ----');`\n","---\n","\n","y la siguiente instrucción para mostrar los resultados:\n","\n","`print('%8.2f %8.2f %6d %6d %6d %8.3f' %(a, b, K, E,k,err_test))`\n","---\n","\n","\n","\n"],"metadata":{"id":"5wMTWdG3xWUH"}},{"cell_type":"markdown","source":["Después de completar la ejecución del programa, podemos extraer conclusiones importantes de los datos obtenidos. En primer lugar, se observa una tendencia clara: a medida que el factor de aprendizaje aumenta, el error de prueba también lo hace, siendo los errores más pequeños notables en valores de aprendizaje de 0.1. Además, se nota que un mayor número de iteraciones generalmente se asocia con un menor error, con algunas excepciones donde a menor número de iteraciones se presenta un menor error de prueba, como se observa en el caso particular de a = 10000.\n","\n","A partir de estas observaciones, no es sorprendente concluir que la mejor configuración para este caso de estudio sería un factor de aprendizaje de 0.1, un margen de 1000.0, k igual a 412. Sin embargo, es importante destacar que en ciertos casos particulares, como a = 10000, la elección óptima puede diferir de esta norma. Estos resultados sugieren la importancia de considerar cuidadosamente el conjunto de parámetros y sus interacciones para lograr un rendimiento óptimo en el modelo."],"metadata":{"id":"sX2_LQw9lfsf"}},{"cell_type":"markdown","source":[],"metadata":{"id":"15mwt5kQAJNJ"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}