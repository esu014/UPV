{"cells":[{"cell_type":"markdown","metadata":{"id":"dB96NTvWTTLE"},"source":["# SIN2324, grupo de laboratorio 3D1\n","# Examen de la práctica 2\n"]},{"cell_type":"markdown","metadata":{"id":"fqjiz9tCTTLG"},"source":["# Regresión logística aplicada a una tarea de openml"]},{"cell_type":"markdown","metadata":{"id":"VdjYFFJTTTLG"},"source":["## 1 Preliminares\n","\n","Las siguientes celdas de código leen una matriz de datos de openml y crean una partición train-test para hacer experimentos:\n","\n","**Pon el ID del dataset que se indique**"]},{"cell_type":"code","source":["pip install openml"],"metadata":{"id":"0uhbuF1hXQ5W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704996225751,"user_tz":-60,"elapsed":23510,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}},"outputId":"e1a94415-4288-4c07-9d2e-292c5a8b3f97"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openml\n","  Downloading openml-0.14.1.tar.gz (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting liac-arff>=2.4.0 (from openml)\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting xmltodict (from openml)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openml) (2.31.0)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from openml) (1.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from openml) (2.8.2)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from openml) (1.5.3)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from openml) (1.11.4)\n","Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from openml) (1.23.5)\n","Collecting minio (from openml)\n","  Downloading minio-7.2.3-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openml) (10.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->openml) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (3.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2023.11.17)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2.0.7)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (23.1.0)\n","Collecting pycryptodome (from minio->openml)\n","  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from minio->openml) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.6)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio->openml) (21.2.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.21)\n","Building wheels for collected packages: openml, liac-arff\n","  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openml: filename=openml-0.14.1-py3-none-any.whl size=146923 sha256=019fda5e71dd6daaf6c399a0050c2f4e321f45b8a6b5517dae03c3c82738cd11\n","  Stored in directory: /root/.cache/pip/wheels/75/bc/fd/739778254a2881ef96b139d0aaf60c6d4f9130bb1459b48f10\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=e47648faa1f37a7622666a4a6fa85ca70044ae1ba870f80b0244b450f84baa07\n","  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n","Successfully built openml liac-arff\n","Installing collected packages: xmltodict, pycryptodome, liac-arff, minio, openml\n","Successfully installed liac-arff-2.5.0 minio-7.2.3 openml-0.14.1 pycryptodome-3.20.0 xmltodict-0.13.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"d78w3LqmTTLH","executionInfo":{"status":"ok","timestamp":1704996238817,"user_tz":-60,"elapsed":1054,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}}},"outputs":[],"source":["import warnings; warnings.filterwarnings(\"ignore\"); import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"telMgz5PTTLI","executionInfo":{"status":"ok","timestamp":1704996242492,"user_tz":-60,"elapsed":2034,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}}},"outputs":[],"source":["data_id = 29    # Poner el id del dataset\n","X, y = fetch_openml(data_id=data_id, return_X_y=True, as_frame=False)\n","mask = ~np.isnan(X).any(axis=1); X = X[mask, :]; y = y[mask]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)"]},{"cell_type":"markdown","source":["**Pregunta 1:** $\\;$ Indica el nº de muestras, nº de características y nº de clases del dataset"],"metadata":{"id":"YThObOWjcjAT"}},{"cell_type":"code","source":["# Escribe el código necesario:\n","# Número de muestras, características y clases en el conjunto de datos\n","num_muestras, num_caracteristicas = X.shape\n","num_clases = len(np.unique(y))\n","print(\"Número de muestras:\", num_muestras)\n","print(\"Número de características:\", num_caracteristicas)\n","print(\"Número de clases:\", num_clases)\n"],"metadata":{"id":"wq0Hqd92cy33","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704996705215,"user_tz":-60,"elapsed":27,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}},"outputId":"3d40dd47-bd58-4c58-e036-211f705713a3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Número de muestras: 653\n","Número de características: 15\n","Número de clases: 2\n"]}]},{"cell_type":"markdown","source":["**Respuesta 1:** $\\;$ Escribe una respuesta breve.\n","Número de muestras: 653\n","Número de características: 15\n","Número de clases: 2"],"metadata":{"id":"ACc6a39WdAxk"}},{"cell_type":"markdown","metadata":{"id":"4r8Y_EMUTTLI"},"source":["## 2 Experimento básico con regresión logística\n","\n","Calcula el error de entrenamiento y de prueba de regresión logística con los valores por omisión que emplea la implementación de sklearn (usa siempre random_state=23) :"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ViCsHZFMTTLI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704998383374,"user_tz":-60,"elapsed":499,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}},"outputId":"718ec145-5fc5-4cc8-9de0-dd0dddcab7d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error de entrenamiento: 0.17816091954022983\n","Error de prueba: 0.13740458015267176\n"]}],"source":["# Escribe el código: ha de escribir \"Error de train: <error>% Error de test: <error>%\"\n","# Usa en todo el examen 'random_state=23'\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","modelo_logistico = LogisticRegression(random_state=23).fit(X_train, y_train)\n","y_train_pred = modelo_logistico.predict(X_train)\n","y_test_pred = modelo_logistico.predict(X_test)\n","error_entrenamiento = 1 - accuracy_score(y_train, y_train_pred)\n","error_prueba = 1 - accuracy_score(y_test, y_test_pred)\n","print(f\"Error de train: {error_entrenamiento * 100:.2f}% Error de test: {error_prueba * 100:.2f}%\")\n"]},{"cell_type":"markdown","source":["**Pregunta 2:** ¿El algoritmo converje?"],"metadata":{"id":"Mj-FMH9zWO19"}},{"cell_type":"markdown","source":["**Respuesta 2:** $\\;$ Sí, con la configuración proporcionada en el código es probable que el algoritmo de regresión logística converja en la mayoría de los casos."],"metadata":{"id":"V6U012asWYL9"}},{"cell_type":"markdown","metadata":{"id":"a2ucMcv9TTLJ"},"source":["## 3 Comparación de solvers\n","\n","Sklearn utiliza el solver 'solver=lbfgs' por omisión. Calcula el error en prueba de regresión logística con otros solvers y 'max_iter=10000':"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"_231aFv-TTLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704997617324,"user_tz":-60,"elapsed":743,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}},"outputId":"6b67100d-e8d8-43b3-950e-83c76a3f4807"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error de test después de entrenar con el solver lbfgs: 8.40%\n","Error de test después de entrenar con el solver liblinear: 8.40%\n","Error de test después de entrenar con el solver newton-cg: 8.40%\n","Error de test después de entrenar con el solver newton-cholesky: 8.40%\n","Error de test después de entrenar con el solver sag: 34.35%\n","Error de test después de entrenar con el solver saga: 35.11%\n"]}],"source":["# Escribe el código: para cada solver probado ha de escribir una línea\n","# \"Error de test después de entrenar con el solver <solver>: <error>%\"\n","solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n","for solver in solvers:\n","    modelo_logistico = LogisticRegression( random_state=23, solver=solver, max_iter=10000).fit(X_train, y_train)\n","    y_test_pred = modelo_logistico.predict(X_test)\n","    error_prueba = 1 - accuracy_score(y_test, y_test_pred)\n","    print(f\"Error de test después de entrenar con el solver {solver}: {error_prueba * 100:.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"nQ8DnlYgTTLJ"},"source":["**Pregunta 3:** $\\;$ ¿El error obtenido con lbfgs coincide con el del experimento básico? Si no, ¿cómo lo explicas?"]},{"cell_type":"markdown","metadata":{"id":"z2hI9WGXTTLK"},"source":["**Respuesta 3:** $\\;$ No coincide, esto se debe a que podría atribuirse a la variabilidad inherente en los resultados de la regresión logística debido a factores como la inicialización aleatoria de los pesos del modelo, la sensibilidad a los datos y posibles diferencias en la configuración específica del solver."]},{"cell_type":"markdown","metadata":{"id":"x4E9MoSRTTLK"},"source":["## 4 Comparación de tolerancias\n","\n","Scikit-learn utiliza una tolerancia 'tol=1e-4' por defecto. Utilizando 'max_iter=10000', calcula el error en la prueba de regresión logística con tolerancias inferiores y superiores al valor por defecto:"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"eK4OpficTTLK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704997939303,"user_tz":-60,"elapsed":1083,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}},"outputId":"1c2e0590-aae5-4403-ae80-ee6cafca5aac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error de test con tolerancia 0.0001: 8.4%\n","Error de test con tolerancia 0.01: 8.4%\n","Error de test con tolerancia 1: 8.4%\n","Error de test con tolerancia 100.0: 17.6%\n","Error de test con tolerancia 10000.0: 34.4%\n"]}],"source":["# Escribe el código: por cada tolerancia probada, ha de escribir una línea\n","# \"Error de test con tolerancia <tol>: <error>%\"\n","tols = [1e-4, 1e-2, 1, 1e2, 1e4]\n","for tol in tols:\n","    modelo_logistico = LogisticRegression(tol=tol, random_state=23, max_iter=10000).fit(X_train, y_train)\n","    err_test = 1 - accuracy_score(y_test, modelo_logistico.predict(X_test))\n","    print(f\"Error de test con tolerancia {tol}: {err_test:.1%}\")"]},{"cell_type":"markdown","metadata":{"id":"lUVCpkIdTTLL"},"source":["**Pregunta 4:** $\\;$ ¿Que crees que pasa cuando la tolerancia es muy elevada?"]},{"cell_type":"markdown","metadata":{"id":"KJ6SYyOfTTLL"},"source":["**Respuesta 4:** $\\;$ Cuando la tolerancia es muy elevada, el porcentaje de error se dispara. En valores hasta 1 mantiene su error, pero en cuanto llegamos a 100, se dispara (en este caso duplicandose)"]},{"cell_type":"markdown","metadata":{"id":"-upZNshQTTLM"},"source":["## 5 Comparación de valores para el máximo número de iteraciones"]},{"cell_type":"markdown","metadata":{"id":"OD4u5I9_TTLM"},"source":["Scikit-learn utiliza 'max_iter=100' por defecto. Sin embargo, como hicimos anteriormente, es conveniente utilizar un valor mayor que facilite la convergencia del algoritmo de entrenamiento y la interpretación de los resultados. Utilizando los mejores valores encontrados previamente para el solver y la tolerancia, calcula el error en la prueba de regresión logística con valores que incluyan 100 y 10000:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"jem7quNRTTLN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704997952552,"user_tz":-60,"elapsed":673,"user":{"displayName":"Enrique Sopeña Urbano","userId":"11205075777714179739"}},"outputId":"2a3c2225-3a8f-433e-ad93-db7c4525b96a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error de test con max_iter 10: 34.4%\n","Error de test con max_iter 20: 34.4%\n","Error de test con max_iter 50: 17.6%\n","Error de test con max_iter 100: 13.7%\n","Error de test con max_iter 10000: 8.4%\n","Error de test con max_iter 100000: 8.4%\n"]}],"source":["# Escribe el código: para cada valor de max_iter probado ha de escribir una línea\n","# \"Error de test con max_iter <max_iter>: <error>%\"\n","max_iters = [10, 20, 50, 100, 10000, 100000]\n","for max_iter in max_iters:\n","    modelo_logistico = LogisticRegression(random_state=23, max_iter=max_iter).fit(X_train, y_train)\n","    err_test = 1 - accuracy_score(y_test, modelo_logistico.predict(X_test))\n","    print(f\"Error de test con max_iter {max_iter}: {err_test:.1%}\")"]},{"cell_type":"markdown","metadata":{"id":"y2kLAaQGTTLN"},"source":["**Pregunta 5:** $\\;$ Con valores optimizados para el solver y la tolerancia, ¿cuántas iteraciones como mínimo se requieren para lograr un error mínimo en la prueba?"]},{"cell_type":"markdown","metadata":{"id":"RwmnDv3eTTLN"},"source":["**Respuesta 5:** $\\;$ Como mínimo necesitamos 10000 iteraciones."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4,"colab":{"provenance":[{"file_id":"1TCGdKSrVDKYUxyiw5zEGw2G1zBcJA8p4","timestamp":1704998557489}]}},"nbformat":4,"nbformat_minor":0}